{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在Pytorch中，神经网络通过torch.nn包来构建。\n",
    "一个nn.Module包括层和一个forward方法，它将返回输出\n",
    "<br>\n",
    "一个典型的神经网络训练过程应该包括以下几点：\n",
    "\n",
    "    1. 定义一个可训练参数的神经网络\n",
    "    2. 迭代整个输入\n",
    "    3. 通过神经网络处理输入\n",
    "    4. 计算损失\n",
    "    5. 反向传播梯度到神经网络的参数\n",
    "    6. 更新网络的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyModel(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 定义一个神经网络\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    \"\"\"\n",
    "    开始定义自己模型的层和方法\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = func.max_pool2d(func.relu(self.conv1(x)), (2, 2))\n",
    "        x = func.max_pool2d(func.relu(self.conv2(x)), (2, 2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = func.relu(self.fc1(x))\n",
    "        x = func.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "    \n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "model = MyModel()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n",
      "torch.Size([6])\n",
      "torch.Size([16, 6, 5, 5])\n",
      "torch.Size([16])\n",
      "torch.Size([120, 400])\n",
      "torch.Size([120])\n",
      "torch.Size([84, 120])\n",
      "torch.Size([84])\n",
      "torch.Size([10, 84])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# 一个模型可训练的参数可以通过调用net.parameters()返回\n",
    "params = list(model.parameters())\n",
    "print(len(params))\n",
    "for param in params:\n",
    "    print(param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0717,  0.0864,  0.0768,  0.0818,  0.0466, -0.0705, -0.1025,  0.1148,\n",
      "          0.0151, -0.0563]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 让我们常识随机输入一个32 * 32的输入，注意，上述定义的网络期望的输入就是32 * 32\n",
    "\n",
    "test_data = torch.randn(1, 1, 32, 32)\n",
    "out = model(test_data)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把所有参数梯度清零，用随机的梯度来反向传播\n",
    "model.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3878, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 演示如何利用反向传播，对模型的参数进行更新\n",
    "out = model(test_data)\n",
    "target = torch.randn(1, 10)\n",
    "criterion = nn.MSELoss()\n",
    "loss = criterion(out, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "tensor([-2.6912e-03,  5.1811e-03, -5.9812e-03, -7.1785e-05,  3.1091e-04,\n",
      "        -1.2411e-02])\n"
     ]
    }
   ],
   "source": [
    "# 同样清空模型参数原有累计的梯度\n",
    "model.zero_grad()\n",
    "print(model.conv1.bias.grad)\n",
    "loss.backward()\n",
    "print(model.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在实际优化的时候，通常是使用工具而不是手动更新\n",
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "out = model(test_data)\n",
    "loss = criterion(out, target)\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "# 注意下列语句会引入pillow module中的PILLOW_VISION，这个包在7.0中已经被移除了，故pip install pillow==6.1\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torchvision是Pytorch内置数据集，也包含了常用的数据处理工具\n",
    "- torchvision.datasets 包含常用的数据集，例如minist,COCO等等\n",
    "- torchvision.models包含常用的著名网络结构，AlexNet, VGG, ResNet等等\n",
    "- torchvision.transforms是Pytorch中对图像处理的包\n",
    "\n",
    "现列出用于图像处理的transforms中的主要函数\n",
    "<br>transforms.ToTensor()方法一个返回一个可以将shape为(H, W, C)的张量变成(C, H, W)形状的方法\n",
    "<br>transforms.ToPILImage()方法返回一个可以将shape为(C, H, W)的张量变成(H, W, C)形状的方法\n",
    "<br>transforms.Scale(size)方法返回一个可以改变输入图像到指定大小的方法。其中size为图像的最短边长(长或者宽)，该方法是按比例缩放。\n",
    "<br>transforms.Normalize(mean, std): 给定均值和标准差，返回一个可以正则化图形的函数。\n",
    "<br>transforms.Pad(padding, fill=0),padding代表要填充的像素， file代表要填充的颜色，fill默认值为0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1182, 665)\n",
      "(888, 500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fang/anaconda3/envs/chenguang/lib/python3.7/site-packages/torchvision/transforms/transforms.py:219: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
      "  warnings.warn(\"The use of the transforms.Scale transform is deprecated, \" +\n"
     ]
    }
   ],
   "source": [
    "# 使用Scale示例\n",
    "from PIL import Image\n",
    "scaler = transforms.Scale(500)\n",
    "image = Image.open(\"./example.jpeg\")\n",
    "print(image.size)\n",
    "print(scaler(image).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665, 1182, 3)\n",
      "tensor([0.1098, 0.1373, 0.2000])\n",
      "tensor([-0.7804, -0.7255, -0.6000])\n"
     ]
    }
   ],
   "source": [
    "# 使用normalize示例\n",
    "import numpy as np\n",
    "image_array = np.asarray(image)\n",
    "print(image_array.shape)\n",
    "image_tensor = transforms.ToTensor()(image_array)\n",
    "image_norm = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(image_tensor)\n",
    "print(image_tensor[:, 0, 0])\n",
    "print(image_norm[:, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28 41 64]\n",
      " [28 41 64]\n",
      " [28 41 64]\n",
      " [28 41 64]\n",
      " [28 41 64]\n",
      " [28 41 64]]\n",
      "(6, 6, 3)\n",
      "[[ 0  0  0]\n",
      " [28 41 64]\n",
      " [28 41 64]\n",
      " [28 41 64]\n",
      " [28 41 64]\n",
      " [28 41 64]\n",
      " [28 41 64]\n",
      " [ 0  0  0]]\n",
      "(8, 8, 3)\n"
     ]
    }
   ],
   "source": [
    "# 使用Pad示例\n",
    "image_resize = transforms.Resize((6, 6))(image)\n",
    "print(np.asarray(image_resize)[0])\n",
    "print(np.asarray(image_resize).shape)\n",
    "image_pad = transforms.Pad(padding=1, fill=0)(image_resize)\n",
    "print(np.asarray(image_pad)[1])\n",
    "print(np.asarray(image_pad).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train = True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train = False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 4, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "# 展示一些数据集中的训练图片\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#function to show an image\n",
    "def image_show(image: torch.Tensor):\n",
    "    image = image / 2  + 0.5 # unnormalize\n",
    "    np_image = image.numpy()\n",
    "    plt.imshow(np.transpose(np_image, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "data_iter = iter(trainloader)\n",
    "images, labels = data_iter.next()\n",
    "image_show(torchvision.utils.make_grid(images))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 定义一个新的可以用来分类上述数据的CNN model\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(func.relu(self.conv1(x)))\n",
    "        x = self.pool(func.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = func.relu(self.fc1(x))\n",
    "        x = func.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model = Classifier()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.087\n",
      "[1,  4000] loss: 1.086\n",
      "[1,  6000] loss: 1.108\n",
      "[1,  8000] loss: 1.084\n",
      "[1, 10000] loss: 1.099\n",
      "[1, 12000] loss: 1.112\n",
      "[2,  2000] loss: 1.004\n",
      "[2,  4000] loss: 1.020\n",
      "[2,  6000] loss: 1.031\n",
      "[2,  8000] loss: 1.017\n",
      "[2, 10000] loss: 1.042\n",
      "[2, 12000] loss: 1.038\n",
      "[3,  2000] loss: 0.936\n",
      "[3,  4000] loss: 0.957\n",
      "[3,  6000] loss: 0.980\n",
      "[3,  8000] loss: 0.951\n",
      "[3, 10000] loss: 0.969\n",
      "[3, 12000] loss: 0.985\n"
     ]
    }
   ],
   "source": [
    "# 定义一个损失函数和优化器，再在数据迭代器上训练模型即可\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "for epoch in range(3):\n",
    "    runniing_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        runniing_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, runniing_loss / 2000))\n",
    "            runniing_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([0.1034, 0.1082, 0.1159, 0.1119], grad_fn=<MaxBackward0>),\n",
      "indices=tensor([8, 8, 8, 8]))\n",
      "tensor([0, 4, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "predicted = torch.max(model(images), 1)\n",
    "print(predicted)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the net work on the 10000 test images: 62 %\n"
     ]
    }
   ],
   "source": [
    "# 输出经过训练的模型在测试集上的准确率。\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(\"Accuracy of the net work on the 10000 test images: %d %%\" % (100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.879\n",
      "[1,  4000] loss: 0.929\n",
      "[1,  6000] loss: 0.937\n",
      "[1,  8000] loss: 0.935\n",
      "[1, 10000] loss: 0.937\n",
      "[1, 12000] loss: 0.922\n",
      "[2,  2000] loss: 0.843\n",
      "[2,  4000] loss: 0.871\n",
      "[2,  6000] loss: 0.891\n",
      "[2,  8000] loss: 0.883\n",
      "[2, 10000] loss: 0.904\n",
      "[2, 12000] loss: 0.901\n",
      "[3,  2000] loss: 0.799\n",
      "[3,  4000] loss: 0.824\n",
      "[3,  6000] loss: 0.830\n",
      "[3,  8000] loss: 0.899\n",
      "[3, 10000] loss: 0.845\n",
      "[3, 12000] loss: 0.870\n"
     ]
    }
   ],
   "source": [
    "# 尝试使用GPU训练模型\n",
    "model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "for epoch in range(3):\n",
    "    runniing_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        runniing_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.3f' %(epoch + 1, i + 1, runniing_loss / 2000))\n",
    "            runniing_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch中的数据并行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在pytorch中，使用DataParallel可以实现多GPU同时操作数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 先将模型移动到一个GPU中\n",
    "device = torch.device(\"cuda:0\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 然后将训练数据也移动到GPU中。例如，将inputs移动到GPU上\n",
    "data_iter = iter(trainloader)\n",
    "inputs, labels = data_iter.next()\n",
    "inputs = inputs.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设计一个小例子\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "input_size = 5\n",
    "output_size = 2\n",
    "batch_size = 30\n",
    "data_size = 100\n",
    "\n",
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 一个实验性的数据集，需要自己实现getitem()方法\n",
    "class RandomDataset(Dataset):\n",
    "    def __init__(self, size, length):\n",
    "        self.length = length\n",
    "        self.data = torch.randn(self.length, size)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "rand_loader = DataLoader(dataset=RandomDataset(input_size, data_size), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = self.fc(x)\n",
    "        print(\"\\tIn Model: input size:\", x.size(), \"output size: \", outputs.size())\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Model(\n",
       "    (fc): Linear(in_features=5, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(input_size, output_size)\n",
    "model = nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tIn Model: input_size: torch.Size([30, 5]) output size:  torch.Size([30, 2])\n",
      "Outsize: input size torch.Size([30, 5]) output size torch.Size([30, 2])\n",
      "\tIn Model: input_size: torch.Size([30, 5]) output size:  torch.Size([30, 2])\n",
      "Outsize: input size torch.Size([30, 5]) output size torch.Size([30, 2])\n",
      "\tIn Model: input_size: torch.Size([30, 5]) output size:  torch.Size([30, 2])\n",
      "Outsize: input size torch.Size([30, 5]) output size torch.Size([30, 2])\n",
      "\tIn Model: input_size: torch.Size([10, 5]) output size:  torch.Size([10, 2])\n",
      "Outsize: input size torch.Size([10, 5]) output size torch.Size([10, 2])\n"
     ]
    }
   ],
   "source": [
    "for data in rand_loader:\n",
    "    inputs = data.to(device)\n",
    "    outputs = model(inputs)\n",
    "    print(\"Outsize: input size\", inputs.size(), \"output size\", outputs.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述过程，由于编码本脚本的电脑只有一片GPU，所以在一次迭代的时候输入大小为[30, 5]，如果有多个GPU，那么每一个GPU上的输入为[30/gpu_num, 5]，并行运行，然后再合并所有的结果，所以不管几片GPU，输出的大小永远为[30, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chenguang",
   "language": "python",
   "name": "chenguang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
