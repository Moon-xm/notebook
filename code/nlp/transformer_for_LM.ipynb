{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一个短小的Transformer示例\n",
    "\n",
    "示例参考PyTorch官方[tutorial](https://pytorch.org/tutorials/beginner/transformer_tutorial.html)\n",
    "\n",
    "在我的笔记中，我是推荐度[The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html),它的代码更加简洁明了，容易读懂，这个教程是参照官方是示例添加的中文注释。\n",
    "\n",
    "如果是先读了哈佛NLP的代码在看这个代码，你会觉得有些奇怪，因为它们输入的形状略有不同。\n",
    "\n",
    "在PyTorch官方的代码实现中，输入输出的形状为:\n",
    "- src -- Encoder的输入序列, 形状为$\\text{[S, N, E]}$\n",
    "- tgt -- Decoder的输入序列, 形状为$\\text{[T, N, E]}$\n",
    "- src_mask -- src序列的上三角掩码, 形状为$\\text{[S, S]}$\n",
    "- tgt_mask -- tgt序列的上三角掩码, 形状为$\\text{[T, T]}$\n",
    "- memory_mask -- Encoder输出的三角掩码掩码, 形状为$\\text{T, S}$\n",
    "- src_key_padding_mask -- src序列的padding掩码，掩盖掉padding补全位置的信息，形状为$\\text{[N, S]}$\n",
    "- tgt_key_padding_mask -- tgt序列的padding掩码，掩盖掉padding补全位置的信息，形状为$\\text{[N, T]}$\n",
    "- memory_key_padding_mask -- memory矩阵的padding掩码，掩盖掉src padding补全位置的信息，形状为$\\text{[N, S]}$\n",
    "\n",
    "其中的$\\text{S, T, N, E}$分别为源序列长度、目标序列长度、Batch size以及Embedding的长度。\n",
    "\n",
    "这些输出的形状很关键，这会影响到数据集准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import copy\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个获取位置编码的模型。得到的矩阵是一个普通的Tensor而不是torch.nn.Parameter对象\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * \n",
    "                             (-math.log(10000) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        # 考虑到Transformer的输入为[S, N, E], 将PE矩阵拓展成[max_len, 1, dim_embed]\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 此处的加法， pe的dimension 1 为1，维度不同会触发广播机制。\n",
    "        x = x + self.pe[: x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, dim_embed, nhead, nhid, nlayers, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.model_type = \"transformer\"\n",
    "        self.src_mask = None\n",
    "        self.dim_embed = dim_embed\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=dim_embed)\n",
    "        self.pos_encoder = PositionalEncoding(dim_embed, dropout=dropout)\n",
    "        encoder_layer = TransformerEncoderLayer(dim_embed, nhead, nhid, dropout=dropout)\n",
    "        self.encoder = TransformerEncoder(encoder_layer=encoder_layer, num_layers=nlayers)\n",
    "        self.decoder = nn.Linear(dim_embed, vocab_size)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        # 对模型的参数进行初始化\n",
    "        init_range = 0.1\n",
    "        self.embedding.weight.data.uniform_(-init_range, init_range)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-init_range, init_range)\n",
    "        \n",
    "    def _generate_square_subsequent_mask(self, size):\n",
    "        \"\"\"\n",
    "        生成一个参数size * size大小的方阵，该方阵的对角线以上的区域取值为float(\"-inf\")\n",
    "        其余区域的取值为0，这个方阵被用于做加法到Attention机制的计算出的注意力矩阵中。\n",
    "        它的目的是为了让序列中时刻t的变量不看到它之后的变量\n",
    "        连续语言模型或者Transformer的Decoder的掩码矩阵，就可以明白\n",
    "        \"\"\"\n",
    "        mask = (torch.triu(torch.ones(size, size)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf'))\n",
    "        return mask.masked_fill(mask == 1, float(0.0))\n",
    "    \n",
    "    def forward(self, src):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            self.src_mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "        src = self.embedding(src) * math.sqrt(self.dim_embed)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.encoder(src, mask=self.src_mask)\n",
    "        return self.decoder(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构造训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "TEXT = torchtext.data.Field(tokenize=get_tokenizer(\"basic_english\"), \n",
    "                            init_token='<sos>', \n",
    "                            eos_token='<eos>', \n",
    "                            lower=True)\n",
    "# 使用torchtext自带的数据集，这个数据集如果本地没有，会从服务器下载到root='.data',dirname=\"WikiText2\"的目录中\n",
    "train_txt, val_txt, test_txt = torchtext.datasets.WikiText2.splits(TEXT)\n",
    "TEXT.build_vocab(train_txt)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(data, batch_size=10):\n",
    "    data = TEXT.numericalize([data.examples[0].text])\n",
    "    nbatch = data.size(0)// batch_size\n",
    "    # data的shape为[length, 1], 在构造成批数据的时候，需要保证length % batch_size==0\n",
    "    data = data.narrow(0, 0, nbatch * batch_size)\n",
    "    # 此处使用转置是为了将返回的数据构造成[N, S]的形状\n",
    "    data = data.view(batch_size, -1).t().contiguous()\n",
    "    return data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "eval_batch_size = 10\n",
    "train_data = batchify(train_txt, batch_size)\n",
    "val_data = batchify(val_txt, eval_batch_size)\n",
    "test_data = batchify(test_txt, eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 35\n",
    "def get_batch(source: torch.Tensor):\n",
    "    for batch, index in enumerate(range(0, source.size(0) - 1, bptt)):\n",
    "        seq_len = min(bptt, len(source) - 1 - index)\n",
    "        data = source[index: index + seq_len]\n",
    "        target = source[index + 1: index + 1 + seq_len].view(-1)\n",
    "        yield batch, data, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(TEXT.vocab.stoi)\n",
    "dim_embed = 200\n",
    "nhid = 200 # Encoder中FeedForward层的隐藏层神经元个数\n",
    "nlayers = 2\n",
    "nhead = 2\n",
    "dropout = 0.2\n",
    "model = TransformerModel(vocab_size, dim_embed, nhead, nhid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data: torch.Tensor):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    start_time = time.time()\n",
    "    log_interval = 400\n",
    "    total_batchs = len(train_data) // bptt\n",
    "    for batch, data, targets in get_batch(train_data):\n",
    "        optimizer.zero_grad()\n",
    "        output =  model(data)\n",
    "        loss = criterion(output.view(-1, vocab_size), targets)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            # epoch的值由运行时命名空间提供\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | lr {:02.2f} | {:5.2f} ms/batch |' \n",
    "                  'loss {:5.2f} | ppl {:8.2f}'.format(epoch, batch, total_batchs, \n",
    "                                                      scheduler.get_lr()[0], \n",
    "                                                      elapsed * 1000 / log_interval, cur_loss, \n",
    "                                                      math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval()\n",
    "    total_loss = 0\n",
    "    vocab_size = len(TEXT.vocab.stoi)\n",
    "    with torch.no_grad():\n",
    "        for batch, data, target in get_batch(data_source):\n",
    "            output = eval_model(data)\n",
    "            output_flat = output.view(-1, vocab_size)\n",
    "            total_loss += len(data) * criterion(output_flat, target).item()\n",
    "    return total_loss / (len(data_source) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   400/ 2981 batches | lr 5.00 | 10.64 ms/batch |loss  7.40 | ppl  1642.61\n",
      "| epoch   1 |   800/ 2981 batches | lr 5.00 | 10.62 ms/batch |loss  6.30 | ppl   546.74\n",
      "| epoch   1 |  1200/ 2981 batches | lr 5.00 | 10.63 ms/batch |loss  6.10 | ppl   446.87\n",
      "| epoch   1 |  1600/ 2981 batches | lr 5.00 | 10.63 ms/batch |loss  6.05 | ppl   422.01\n",
      "| epoch   1 |  2000/ 2981 batches | lr 5.00 | 10.63 ms/batch |loss  5.96 | ppl   386.34\n",
      "| epoch   1 |  2400/ 2981 batches | lr 5.00 | 10.63 ms/batch |loss  5.87 | ppl   354.21\n",
      "| epoch   1 |  2800/ 2981 batches | lr 5.00 | 10.66 ms/batch |loss  5.85 | ppl   348.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 33.37s | valid loss  5.82 | valid ppl   337.95\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |   400/ 2981 batches | lr 4.51 | 10.66 ms/batch |loss  5.79 | ppl   327.03\n",
      "| epoch   2 |   800/ 2981 batches | lr 4.51 | 10.66 ms/batch |loss  5.62 | ppl   275.47\n",
      "| epoch   2 |  1200/ 2981 batches | lr 4.51 | 10.66 ms/batch |loss  5.60 | ppl   270.90\n",
      "| epoch   2 |  1600/ 2981 batches | lr 4.51 | 10.66 ms/batch |loss  5.65 | ppl   284.41\n",
      "| epoch   2 |  2000/ 2981 batches | lr 4.51 | 10.68 ms/batch |loss  5.60 | ppl   271.55\n",
      "| epoch   2 |  2400/ 2981 batches | lr 4.51 | 10.70 ms/batch |loss  5.55 | ppl   257.04\n",
      "| epoch   2 |  2800/ 2981 batches | lr 4.51 | 10.69 ms/batch |loss  5.55 | ppl   258.19\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 33.50s | valid loss  5.55 | valid ppl   258.33\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |   400/ 2981 batches | lr 4.29 | 10.69 ms/batch |loss  5.56 | ppl   259.01\n",
      "| epoch   3 |   800/ 2981 batches | lr 4.29 | 10.69 ms/batch |loss  5.40 | ppl   220.81\n",
      "| epoch   3 |  1200/ 2981 batches | lr 4.29 | 10.69 ms/batch |loss  5.40 | ppl   221.30\n",
      "| epoch   3 |  1600/ 2981 batches | lr 4.29 | 10.70 ms/batch |loss  5.47 | ppl   236.53\n",
      "| epoch   3 |  2000/ 2981 batches | lr 4.29 | 10.70 ms/batch |loss  5.43 | ppl   228.92\n",
      "| epoch   3 |  2400/ 2981 batches | lr 4.29 | 10.71 ms/batch |loss  5.38 | ppl   216.78\n",
      "| epoch   3 |  2800/ 2981 batches | lr 4.29 | 10.71 ms/batch |loss  5.39 | ppl   219.11\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 33.57s | valid loss  5.56 | valid ppl   259.64\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 |   400/ 2981 batches | lr 4.07 | 10.72 ms/batch |loss  5.41 | ppl   222.72\n",
      "| epoch   4 |   800/ 2981 batches | lr 4.07 | 10.70 ms/batch |loss  5.25 | ppl   190.25\n",
      "| epoch   4 |  1200/ 2981 batches | lr 4.07 | 10.71 ms/batch |loss  5.26 | ppl   192.62\n",
      "| epoch   4 |  1600/ 2981 batches | lr 4.07 | 10.71 ms/batch |loss  5.33 | ppl   205.69\n",
      "| epoch   4 |  2000/ 2981 batches | lr 4.07 | 10.71 ms/batch |loss  5.30 | ppl   200.85\n",
      "| epoch   4 |  2400/ 2981 batches | lr 4.07 | 10.72 ms/batch |loss  5.24 | ppl   188.07\n",
      "| epoch   4 |  2800/ 2981 batches | lr 4.07 | 10.73 ms/batch |loss  5.26 | ppl   192.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 33.63s | valid loss  5.50 | valid ppl   243.74\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 |   400/ 2981 batches | lr 3.87 | 10.74 ms/batch |loss  5.28 | ppl   196.18\n",
      "| epoch   5 |   800/ 2981 batches | lr 3.87 | 10.74 ms/batch |loss  5.12 | ppl   168.08\n",
      "| epoch   5 |  1200/ 2981 batches | lr 3.87 | 10.75 ms/batch |loss  5.15 | ppl   172.55\n",
      "| epoch   5 |  1600/ 2981 batches | lr 3.87 | 10.76 ms/batch |loss  5.21 | ppl   183.34\n",
      "| epoch   5 |  2000/ 2981 batches | lr 3.87 | 10.77 ms/batch |loss  5.19 | ppl   179.32\n",
      "| epoch   5 |  2400/ 2981 batches | lr 3.87 | 10.78 ms/batch |loss  5.13 | ppl   168.21\n",
      "| epoch   5 |  2800/ 2981 batches | lr 3.87 | 10.79 ms/batch |loss  5.15 | ppl   172.50\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 33.77s | valid loss  5.48 | valid ppl   240.36\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |   400/ 2981 batches | lr 3.68 | 10.78 ms/batch |loss  5.18 | ppl   178.07\n",
      "| epoch   6 |   800/ 2981 batches | lr 3.68 | 10.80 ms/batch |loss  5.02 | ppl   151.98\n",
      "| epoch   6 |  1200/ 2981 batches | lr 3.68 | 10.81 ms/batch |loss  5.05 | ppl   155.48\n",
      "| epoch   6 |  1600/ 2981 batches | lr 3.68 | 10.83 ms/batch |loss  5.11 | ppl   166.29\n",
      "| epoch   6 |  2000/ 2981 batches | lr 3.68 | 10.84 ms/batch |loss  5.10 | ppl   163.25\n",
      "| epoch   6 |  2400/ 2981 batches | lr 3.68 | 10.83 ms/batch |loss  5.02 | ppl   151.63\n",
      "| epoch   6 |  2800/ 2981 batches | lr 3.68 | 10.84 ms/batch |loss  5.05 | ppl   156.16\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 33.94s | valid loss  5.45 | valid ppl   232.28\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "epochs = 6\n",
    "best_model = None\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_data)\n",
    "    val_loss = evaluate(model, val_data)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.2f} | valid ppl {:8.2f}'.format(\n",
    "        epoch, (time.time() - epoch_start_time), val_loss, math.exp(val_loss)))\n",
    "    print('-' * 89)\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| End of training | test loss  5.36 | test ppl   212.69\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 测试集上的Perplexity为多少\n",
    "best_model.to(device)\n",
    "test_loss = evaluate(best_model, test_data)\n",
    "print('-' * 89)\n",
    "print('| End of training | test loss {:5.2f} | test ppl {:8.2f}'.format(test_loss,  math.exp(test_loss)))\n",
    "print('-' * 89)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chenguang",
   "language": "python",
   "name": "chenguang"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
